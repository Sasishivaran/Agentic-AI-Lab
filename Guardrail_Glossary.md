# üîê Guardrail Glossary ‚Äî Industry Standards (1 Page)

This glossary provides the most common governance and safety guardrails used in Agentic AI systems.

---

## 1. Prompt Injection Protection
Prevents malicious instructions from altering agent behavior.

## 2. PII Masking
Removes or obfuscates personally identifiable information.

## 3. Jailbreak Detection
Identifies attempts to bypass safety constraints.

## 4. Toxicity & Safety Filtering
Blocks harmful or unsafe outputs using classifiers or guard models.

## 5. Token Rate Limiting
Prevents runaway token usage and cost spikes.

## 6. Access Control Policies
Restricts which tools, APIs, or data sources an agent can access.

## 7. Audit Logging
Captures agent actions and tool calls for traceability.

## 8. Secure Tool Invocation
Ensures tools are called with validated inputs and restricted permissions.

## 9. Data Privacy Controls
Implements encryption, anonymization, and secure storage.

## 10. Risk Mitigation Strategy
Defines fallback behaviors and safe-failure modes.

